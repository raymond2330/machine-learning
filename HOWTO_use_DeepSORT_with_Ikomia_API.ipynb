{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XIBGlEafDQf"
   },
   "source": [
    "<img src='https://github.com/Ikomia-dev/notebooks/blob/main/examples/img/banner_ikomia.png?raw=true'>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvouGVeYfDQg"
   },
   "source": [
    "# Easy Object Tracking with DeepSORT\n",
    "\n",
    "**DeepSORT** (Simple Online and Realtime Tracking with a Deep Association Metric) is an extension of the original SORT (Simple Real-time Tracker) algorithm, which is considered an elegant and widely used framework for object tracking. It incorporates a deep learning methodology to address real-world tracking challenges such as occlusions and different viewpoints.\n",
    "\n",
    "![illustration Deepsort](https://learnopencv.com/wp-content/uploads/2022/06/01-sprint-race.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-STLXz8ifDQh"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cV0_2S0SfDQh"
   },
   "source": [
    "You need to install Ikomia Python API with pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cbvRlv_ufDQh",
    "outputId": "e3893478-603b-467b-96a3-b272121649b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ikomia\n",
      "  Downloading ikomia-0.12.0-cp310-none-win_amd64.whl.metadata (792 bytes)\n",
      "Collecting cython (from ikomia)\n",
      "  Downloading Cython-3.0.11-cp310-cp310-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting setuptools==59.5.0 (from ikomia)\n",
      "  Downloading setuptools-59.5.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting numpy<1.24,>=1.20.3 (from ikomia)\n",
      "  Downloading numpy-1.23.5-cp310-cp310-win_amd64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.28.0 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from ikomia) (2.32.3)\n",
      "Collecting mlflow==1.30.0 (from ikomia)\n",
      "  Downloading mlflow-1.30.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tensorboard<3.0,>=2.5.0 (from ikomia)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: Pillow>=8.1.0 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from ikomia) (11.0.0)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.41.0 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from ikomia) (4.67.1)\n",
      "Requirement already satisfied: matplotlib<4.0,>=3.4.3 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from ikomia) (3.9.2)\n",
      "Requirement already satisfied: python-dotenv>=0.18.0 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from ikomia) (1.0.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from ikomia) (6.0.2)\n",
      "Collecting semver<4.0,>=3.0.1 (from ikomia)\n",
      "  Using cached semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from mlflow==1.30.0->ikomia) (8.1.7)\n",
      "Collecting cloudpickle<3 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting databricks-cli<1,>=0.8.7 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting entrypoints<1 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gitpython<4,>=2.1.0 (from mlflow==1.30.0->ikomia)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting protobuf<5,>=3.12.0 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting pytz<2023 (from mlflow==1.30.0->ikomia)\n",
      "  Using cached pytz-2022.7.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting packaging<22 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading packaging-21.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting importlib-metadata!=4.7.0,<6,>=3.7.0 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading importlib_metadata-5.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading sqlparse-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting alembic<2 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<7,>=4.0.0 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading docker-6.1.3-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting Flask<3 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading flask-2.3.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from mlflow==1.30.0->ikomia) (1.14.1)\n",
      "Collecting pandas<2 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading pandas-1.5.3-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting prometheus-flask-exporter<1 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading prometheus_flask_exporter-0.23.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting querystring-parser<2 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\n",
      "Collecting sqlalchemy<2,>=1.4.0 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading SQLAlchemy-1.4.54-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting waitress<3 (from mlflow==1.30.0->ikomia)\n",
      "  Downloading waitress-2.1.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from matplotlib<4.0,>=3.4.3->ikomia) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from matplotlib<4.0,>=3.4.3->ikomia) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from matplotlib<4.0,>=3.4.3->ikomia) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from matplotlib<4.0,>=3.4.3->ikomia) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from matplotlib<4.0,>=3.4.3->ikomia) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from matplotlib<4.0,>=3.4.3->ikomia) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from requests<3.0,>=2.28.0->ikomia) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from requests<3.0,>=2.28.0->ikomia) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from requests<3.0,>=2.28.0->ikomia) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from requests<3.0,>=2.28.0->ikomia) (2024.8.30)\n",
      "Collecting absl-py>=0.4 (from tensorboard<3.0,>=2.5.0->ikomia)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard<3.0,>=2.5.0->ikomia)\n",
      "  Downloading grpcio-1.68.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<3.0,>=2.5.0->ikomia)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from tensorboard<3.0,>=2.5.0->ikomia) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<3.0,>=2.5.0->ikomia)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<3.0,>=2.5.0->ikomia)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from tqdm<5.0,>=4.41.0->ikomia) (0.4.6)\n",
      "Collecting Mako (from alembic<2->mlflow==1.30.0->ikomia)\n",
      "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from alembic<2->mlflow==1.30.0->ikomia) (4.12.2)\n",
      "Collecting pyjwt>=1.7.0 (from databricks-cli<1,>=0.8.7->mlflow==1.30.0->ikomia)\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting oauthlib>=3.1.0 (from databricks-cli<1,>=0.8.7->mlflow==1.30.0->ikomia)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow==1.30.0->ikomia) (0.9.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from docker<7,>=4.0.0->mlflow==1.30.0->ikomia) (1.8.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from docker<7,>=4.0.0->mlflow==1.30.0->ikomia) (308)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from Flask<3->mlflow==1.30.0->ikomia) (3.1.4)\n",
      "Collecting itsdangerous>=2.1.2 (from Flask<3->mlflow==1.30.0->ikomia)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.6.2 (from Flask<3->mlflow==1.30.0->ikomia)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow==1.30.0->ikomia)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow==1.30.0->ikomia)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from prometheus-flask-exporter<1->mlflow==1.30.0->ikomia) (0.21.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy<2,>=1.4.0->mlflow==1.30.0->ikomia)\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\raymond\\desktop\\machine learning\\env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<3.0,>=2.5.0->ikomia) (3.0.2)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow==1.30.0->ikomia)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading ikomia-0.12.0-cp310-none-win_amd64.whl (70.8 MB)\n",
      "   ---------------------------------------- 0.0/70.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.0/70.8 MB 49.2 MB/s eta 0:00:02\n",
      "    --------------------------------------- 1.0/70.8 MB 49.2 MB/s eta 0:00:02\n",
      "    --------------------------------------- 1.0/70.8 MB 49.2 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 2.1/70.8 MB 2.6 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 3.1/70.8 MB 3.0 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 4.2/70.8 MB 3.4 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 4.2/70.8 MB 3.4 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 4.2/70.8 MB 3.4 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 5.2/70.8 MB 2.7 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 5.2/70.8 MB 2.7 MB/s eta 0:00:25\n",
      "   --- ------------------------------------ 6.3/70.8 MB 2.9 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 7.3/70.8 MB 3.0 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 8.4/70.8 MB 3.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 9.4/70.8 MB 3.2 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 10.5/70.8 MB 3.3 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 10.5/70.8 MB 3.3 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 11.5/70.8 MB 3.2 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 12.6/70.8 MB 3.3 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 13.6/70.8 MB 3.3 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 13.6/70.8 MB 3.3 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 14.7/70.8 MB 3.4 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 14.7/70.8 MB 3.4 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 15.7/70.8 MB 3.2 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 16.8/70.8 MB 3.3 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 17.8/70.8 MB 3.3 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 18.6/70.8 MB 3.3 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 18.9/70.8 MB 3.4 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 19.9/70.8 MB 3.4 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 21.0/70.8 MB 3.4 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 21.0/70.8 MB 3.4 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 22.0/70.8 MB 3.4 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 23.1/70.8 MB 3.4 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 24.1/70.8 MB 3.5 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 25.2/70.8 MB 3.5 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 25.2/70.8 MB 3.5 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 26.2/70.8 MB 3.5 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 26.7/70.8 MB 3.4 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 27.3/70.8 MB 3.5 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 28.3/70.8 MB 3.5 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 29.4/70.8 MB 3.5 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 29.4/70.8 MB 3.5 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 29.4/70.8 MB 3.5 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 30.4/70.8 MB 3.4 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 31.5/70.8 MB 3.4 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 31.5/70.8 MB 3.4 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 31.5/70.8 MB 3.4 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 31.5/70.8 MB 3.4 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 31.5/70.8 MB 3.4 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 32.5/70.8 MB 3.2 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 32.5/70.8 MB 3.2 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 33.6/70.8 MB 3.1 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 34.6/70.8 MB 3.1 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 34.6/70.8 MB 3.1 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 35.7/70.8 MB 3.1 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 35.7/70.8 MB 3.1 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 36.7/70.8 MB 3.1 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 36.7/70.8 MB 3.1 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 37.7/70.8 MB 3.1 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 38.8/70.8 MB 3.1 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 39.8/70.8 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 39.8/70.8 MB 3.1 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 40.9/70.8 MB 3.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 41.9/70.8 MB 3.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 43.0/70.8 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 44.0/70.8 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 45.1/70.8 MB 3.3 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 45.1/70.8 MB 3.3 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 46.1/70.8 MB 3.2 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 47.2/70.8 MB 3.3 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 48.2/70.8 MB 3.3 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 48.2/70.8 MB 3.3 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 49.3/70.8 MB 3.3 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 50.3/70.8 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 51.4/70.8 MB 3.3 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 52.4/70.8 MB 3.3 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 52.4/70.8 MB 3.3 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 52.4/70.8 MB 3.3 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 53.5/70.8 MB 3.3 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 53.5/70.8 MB 3.3 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 54.5/70.8 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 54.5/70.8 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 55.6/70.8 MB 3.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 56.6/70.8 MB 3.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 57.4/70.8 MB 3.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 57.7/70.8 MB 3.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 58.7/70.8 MB 3.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 59.8/70.8 MB 3.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 59.8/70.8 MB 3.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 59.8/70.8 MB 3.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 59.8/70.8 MB 3.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 59.8/70.8 MB 3.3 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 60.8/70.8 MB 3.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 61.9/70.8 MB 3.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 61.9/70.8 MB 3.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 62.9/70.8 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 64.0/70.8 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 65.0/70.8 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 66.1/70.8 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 66.1/70.8 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 67.1/70.8 MB 3.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 68.2/70.8 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 68.2/70.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  69.2/70.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  69.2/70.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  70.0/70.8 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  70.5/70.8 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 70.8/70.8 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading mlflow-1.30.0-py3-none-any.whl (17.0 MB)\n",
      "   ---------------------------------------- 0.0/17.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/17.0 MB 52.4 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 2.1/17.0 MB 6.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 3.1/17.0 MB 5.6 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 4.2/17.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 5.2/17.0 MB 5.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 6.3/17.0 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 6.3/17.0 MB 4.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 7.3/17.0 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 8.4/17.0 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 8.4/17.0 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 8.4/17.0 MB 4.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 9.4/17.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 10.5/17.0 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 11.5/17.0 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 12.6/17.0 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 13.6/17.0 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 13.6/17.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 14.7/17.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 15.7/17.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.8/17.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 17.0/17.0 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "   ---------------------------------------- 0.0/952.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 952.4/952.4 kB 46.0 MB/s eta 0:00:00\n",
      "Downloading numpy-1.23.5-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "   ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 14.6/14.6 MB 70.9 MB/s eta 0:00:00\n",
      "Using cached semver-3.0.2-py3-none-any.whl (17 kB)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Downloading Cython-3.0.11-cp310-cp310-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.8/2.8 MB 81.1 MB/s eta 0:00:00\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
      "Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
      "Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading flask-2.3.3-py3-none-any.whl (96 kB)\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading grpcio-1.68.0-cp310-cp310-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.4/4.4 MB 66.7 MB/s eta 0:00:00\n",
      "Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Downloading pandas-1.5.3-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 10.4/10.4 MB 72.1 MB/s eta 0:00:00\n",
      "Downloading prometheus_flask_exporter-0.23.1-py3-none-any.whl (18 kB)\n",
      "Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Downloading SQLAlchemy-1.4.54-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 83.2 MB/s eta 0:00:00\n",
      "Downloading sqlparse-0.5.2-py3-none-any.whl (44 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pytz, zipp, werkzeug, waitress, tensorboard-data-server, sqlparse, smmap, setuptools, semver, querystring-parser, pyjwt, protobuf, packaging, oauthlib, numpy, markdown, Mako, itsdangerous, grpcio, greenlet, entrypoints, cython, cloudpickle, blinker, absl-py, tensorboard, sqlalchemy, pandas, importlib-metadata, gitdb, Flask, docker, databricks-cli, prometheus-flask-exporter, gitpython, alembic, mlflow, ikomia\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2024.2\n",
      "    Uninstalling pytz-2024.2:\n",
      "      Successfully uninstalled pytz-2024.2\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.5.0\n",
      "    Uninstalling setuptools-65.5.0:\n",
      "      Successfully uninstalled setuptools-65.5.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.0\n",
      "    Uninstalling protobuf-5.29.0:\n",
      "      Successfully uninstalled protobuf-5.29.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "  Attempting uninstall: docker\n",
      "    Found existing installation: docker 7.1.0\n",
      "    Uninstalling docker-7.1.0:\n",
      "      Successfully uninstalled docker-7.1.0\n",
      "Successfully installed Flask-2.3.3 Mako-1.3.6 absl-py-2.1.0 alembic-1.14.0 blinker-1.9.0 cloudpickle-2.2.1 cython-3.0.11 databricks-cli-0.18.0 docker-6.1.3 entrypoints-0.4 gitdb-4.0.11 gitpython-3.1.43 greenlet-3.1.1 grpcio-1.68.0 ikomia-0.12.0 importlib-metadata-5.2.0 itsdangerous-2.2.0 markdown-3.7 mlflow-1.30.0 numpy-1.23.5 oauthlib-3.2.2 packaging-21.3 pandas-1.5.3 prometheus-flask-exporter-0.23.1 protobuf-4.25.5 pyjwt-2.10.1 pytz-2022.7.1 querystring-parser-1.2.4 semver-3.0.2 setuptools-59.5.0 smmap-5.0.1 sqlalchemy-1.4.54 sqlparse-0.5.2 tensorboard-2.18.0 tensorboard-data-server-0.7.2 waitress-2.1.2 werkzeug-3.1.3 zipp-3.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Raymond\\Desktop\\Machine Learning\\env\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Raymond\\Desktop\\Machine Learning\\env\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-server 2.14.2 requires packaging>=22.0, but you have packaging 21.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install ikomia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-j3VbsAYfDQi"
   },
   "source": [
    "---\n",
    "\n",
    "*Note: The script is not compatible with Google Colab as they have disabled cv2.imshow()*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download video and cut example video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uBp98pWxiHXq"
   },
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import cv2\n",
    "\n",
    "url = \"https://www.pexels.com/download/video/12116094/?fps=29.97&h=720&w=1280\"\n",
    "\n",
    "# Define headers to mimic a browser request\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, stream=True)\n",
    "with open(\"video.mp4\", \"wb\") as f:\n",
    "    for chunk in response.iter_content(chunk_size=1024):\n",
    "        f.write(chunk)\n",
    "\n",
    "# Replace with the path to your downloaded video\n",
    "video_path = \"video.mp4\"\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video has opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = frame_count / fps\n",
    "cut_frame = int(frame_count / 4)  # Frame to cut the video at\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "out = cv2.VideoWriter('short_video.mp4', fourcc, fps, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "# Read and write frames until the cut point\n",
    "frame_num = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame_num == cut_frame:\n",
    "        break\n",
    "    out.write(frame)\n",
    "    frame_num += 1\n",
    "\n",
    "# Release everything\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run YOLOv7 and DeepSORT on your video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q8dA1vWbfDQi",
    "outputId": "6e55cb62-36d7-4ee8-840d-7289582d6b71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ikomia auto-completion updated for installed plugins.\n",
      "Ikomia auto-completion updated for Ikomia HUB algorithms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer_yolo_v7.zip: 100%|██████████| 9.29M/9.29M [00:01<00:00, 7.86MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing infer_yolo_v7 requirements. This may take a while, please be patient...\n",
      "Ikomia auto-completion updated for installed plugins.\n",
      "Ikomia auto-completion updated for Ikomia HUB algorithms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer_deepsort.zip: 100%|██████████| 10.4M/10.4M [00:01<00:00, 8.25MiB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing infer_deepsort requirements. This may take a while, please be patient...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Algorithm infer_deepsort could not be loaded:<class 'ModuleNotFoundError'>: No module named 'torchreid':   File \"C:\\Users\\Raymond\\Ikomia/Plugins/Python\\infer_deepsort\\infer_deepsort_process.py\", line 23, in <module>\n    from infer_deepsort.deep_sort_pytorch.deep_sort import DeepSort\n\n  File \"C:\\Users\\Raymond\\Ikomia/Plugins/Python\\infer_deepsort\\deep_sort_pytorch\\deep_sort\\__init__.py\", line 1, in <module>\n    from .deep_sort import DeepSort\n\n  File \"C:\\Users\\Raymond\\Ikomia/Plugins/Python\\infer_deepsort\\deep_sort_pytorch\\deep_sort\\deep_sort.py\", line 4, in <module>\n    from .deep.feature_extractor import Extractor\n\n  File \"C:\\Users\\Raymond\\Ikomia/Plugins/Python\\infer_deepsort\\deep_sort_pytorch\\deep_sort\\deep\\feature_extractor.py\", line 8, in <module>\n    from torchreid import models\n (Code 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Raymond\\Desktop\\Machine Learning\\env\\lib\\site-packages\\ikomia\\dataprocess\\registry.py:185\u001b[0m, in \u001b[0;36mIkomiaRegistry.create_algorithm\u001b[1;34m(self, name, parameters, public_hub, private_hub)\u001b[0m\n\u001b[0;32m    184\u001b[0m algo_dir, language \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_algorithm_directory(name)\n\u001b[1;32m--> 185\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m algo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_instance(name, parameters)\n",
      "File \u001b[1;32mc:\\Users\\Raymond\\Desktop\\Machine Learning\\env\\lib\\site-packages\\ikomia\\dataprocess\\registry.py:351\u001b[0m, in \u001b[0;36mIkomiaRegistry._load_algorithm\u001b[1;34m(self, name, directory, language)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(directory):\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlgorithm \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m language \u001b[38;5;241m==\u001b[39m ApiLanguage\u001b[38;5;241m.\u001b[39mPYTHON:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Algorithm infer_deepsort is not installed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m detector \u001b[38;5;241m=\u001b[39m wf\u001b[38;5;241m.\u001b[39madd_task(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfer_yolo_v7\u001b[39m\u001b[38;5;124m\"\u001b[39m, auto_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Add ByteTrack tracking algorithm\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m tracking \u001b[38;5;241m=\u001b[39m \u001b[43mwf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minfer_deepsort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m tracking\u001b[38;5;241m.\u001b[39mset_parameters({\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconf_thres\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m })\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Open the video file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Raymond\\Desktop\\Machine Learning\\env\\lib\\site-packages\\ikomia\\dataprocess\\workflow.py:363\u001b[0m, in \u001b[0;36mWorkflow.add_task\u001b[1;34m(self, task, name, params, auto_connect, public_hub, private_hub)\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to add task to workflow: you must set either a valid name or task instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m     task \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mpublic_hub\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpublic_hub\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mprivate_hub\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate_hub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlgorithm \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be created.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Raymond\\Desktop\\Machine Learning\\env\\lib\\site-packages\\ikomia\\dataprocess\\registry.py:193\u001b[0m, in \u001b[0;36mIkomiaRegistry.create_algorithm\u001b[1;34m(self, name, parameters, public_hub, private_hub)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (public_hub \u001b[38;5;129;01mor\u001b[39;00m private_hub) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m algo_dir:\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;66;03m# Algorithm is not installed, so try to install it from HUB\u001b[39;00m\n\u001b[0;32m    192\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry installing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m from Ikomia HUB...\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstall_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpublic_hub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate_hub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m     algo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_instance(name, parameters)\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;66;03m# If algorithm is installed locally but not functional (algo_dir is not empty), it may be a plugin\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# in developpement and we should not overwrite it with the Ikomia Hub version\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Raymond\\Desktop\\Machine Learning\\env\\lib\\site-packages\\ikomia\\dataprocess\\registry.py:324\u001b[0m, in \u001b[0;36mIkomiaRegistry.install_algorithm\u001b[1;34m(self, name, public_hub, private_hub, force)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_installed_modules(algo_dir)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# Load it\u001b[39;00m\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m language \u001b[38;5;241m==\u001b[39m ApiLanguage\u001b[38;5;241m.\u001b[39mCPP \u001b[38;5;129;01mand\u001b[39;00m update:\n\u001b[0;32m    326\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC++ algorithm \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be reloaded at runtime. It will be updated on next start.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    327\u001b[0m                    plugin[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Raymond\\Desktop\\Machine Learning\\env\\lib\\site-packages\\ikomia\\dataprocess\\registry.py:354\u001b[0m, in \u001b[0;36mIkomiaRegistry._load_algorithm\u001b[1;34m(self, name, directory, language)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlgorithm \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m language \u001b[38;5;241m==\u001b[39m ApiLanguage\u001b[38;5;241m.\u001b[39mPYTHON:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_python_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m language \u001b[38;5;241m==\u001b[39m ApiLanguage\u001b[38;5;241m.\u001b[39mCPP:\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_cpp_algorithm(directory)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Algorithm infer_deepsort could not be loaded:<class 'ModuleNotFoundError'>: No module named 'torchreid':   File \"C:\\Users\\Raymond\\Ikomia/Plugins/Python\\infer_deepsort\\infer_deepsort_process.py\", line 23, in <module>\n    from infer_deepsort.deep_sort_pytorch.deep_sort import DeepSort\n\n  File \"C:\\Users\\Raymond\\Ikomia/Plugins/Python\\infer_deepsort\\deep_sort_pytorch\\deep_sort\\__init__.py\", line 1, in <module>\n    from .deep_sort import DeepSort\n\n  File \"C:\\Users\\Raymond\\Ikomia/Plugins/Python\\infer_deepsort\\deep_sort_pytorch\\deep_sort\\deep_sort.py\", line 4, in <module>\n    from .deep.feature_extractor import Extractor\n\n  File \"C:\\Users\\Raymond\\Ikomia/Plugins/Python\\infer_deepsort\\deep_sort_pytorch\\deep_sort\\deep\\feature_extractor.py\", line 8, in <module>\n    from torchreid import models\n (Code 9)"
     ]
    }
   ],
   "source": [
    "from ikomia.dataprocess.workflow import Workflow\n",
    "from ikomia.utils.displayIO import display\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Replace 'your_video_path.mp4' with the actual video file path\n",
    "input_video_path = 'short_video.mp4'\n",
    "output_video_path = 'deepsort_output_video.avi'\n",
    "\n",
    "# Init your workflow\n",
    "wf = Workflow()\n",
    "\n",
    "# Add object detection algorithm\n",
    "detector = wf.add_task(name=\"infer_yolo_v7\", auto_connect=True)\n",
    "\n",
    "# Add ByteTrack tracking algorithm\n",
    "tracking = wf.add_task(name=\"infer_deepsort\", auto_connect=True)\n",
    "\n",
    "tracking.set_parameters({\n",
    "    \"categories\": \"all\",\n",
    "    \"conf_thres\": \"0.5\",\n",
    "})\n",
    "\n",
    "# Open the video file\n",
    "stream = cv2.VideoCapture(input_video_path)\n",
    "if not stream.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties for the output\n",
    "frame_width = int(stream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = stream.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "# The 'XVID' codec is widely supported and provides good quality\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    # Read image from stream\n",
    "    ret, frame = stream.read()\n",
    "\n",
    "    # Test if the video has ended or there is an error\n",
    "    if not ret:\n",
    "        print(\"Info: End of video or error.\")\n",
    "        break\n",
    "\n",
    "    # Run the workflow on current frame\n",
    "    wf.run_on(array=frame)\n",
    "\n",
    "    # Get results\n",
    "    image_out = tracking.get_output(0)\n",
    "    obj_detect_out = tracking.get_output(1)\n",
    "\n",
    "    # Convert the result to BGR color space for displaying\n",
    "    img_out = image_out.get_image_with_graphics(obj_detect_out)\n",
    "    img_res = cv2.cvtColor(img_out, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Save the resulting frame\n",
    "    out.write(img_out)\n",
    "\n",
    "    # Display\n",
    "    display(img_res, title=\"DeepSORT\", viewer=\"opencv\")\n",
    "\n",
    "    # Press 'q' to quit the video processing\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop release everything\n",
    "stream.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
